import contextlib
import joblib
import numpy as np
import torch
import os
import random

@contextlib.contextmanager
def tqdm_joblib(tqdm_object):
    """Context manager to patch joblib to report into tqdm progress bar given askimage.transform"""
    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):
        def __call__(self, *args, **kwargs):
            tqdm_object.update(n=self.batch_size)
            return super().__call__(*args, **kwargs)

    old_batch_callback = joblib.parallel.BatchCompletionCallBack
    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback
    try:
        yield tqdm_object
    finally:
        joblib.parallel.BatchCompletionCallBack = old_batch_callback
        tqdm_object.close()

def seed_everything(seed=17112000):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

def estimate_maximum_batch_size(model, device, input_shape):
    batch = 1
    model = model.to(device)
    
    while True:
    
        torch.cuda.synchronize()
        x = torch.ones((batch,) + input_shape, dtype=torch.float32).to(device)
        try:
            model(x)
        except torch.cuda.OutOfMemoryError:
            batch = batch // 2

            return batch

        else:
            batch *= 2
import torch
import torch.nn as nn

from ensemble_boxes import soft_nms

from .base import BaseEngine
# from .utils import calculate_mAP
from ..utils import imgs2fig

class FasterRCNN_TorchVision_Engine(BaseEngine):
    def __init__(self, device, model, optimizer, criterion, scheduler, logger=None):
        super(FasterRCNN_TorchVision_Engine, self).__init__(device, model, optimizer, criterion, scheduler, logger)

        self.main_metric = 'MAE'
        self.best_metric = float("inf")
        self.criteria = lambda x,y : x < y

    def _run_epoch(self, loader) -> None:
        n_batch_to_log = torch.randint(0, len(loader), (1,)).item()

        for i, (features, targets, rgbs) in enumerate(loader):
            
            features = [feature.to(self.local_rank) for feature in features]
            targets = [{k: v.to(self.local_rank) for k, v in t.items()} for t in targets]
            batch_size = len(features)

            self.model.train()
            losses = self.model(features, targets)
            loss = sum(loss for loss in losses.values())

            if self.stage == 'train':
                if loss == 0 or not torch.isfinite(loss):
                    continue

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            self.model.eval()
            with torch.no_grad():
                targets = [{key : value.cpu() for key, value in target.items()} for target in targets]
                predictions_non_nms = self.model(features)
                predictions_non_nms = [{key : value.cpu() for key, value in prediction.items()} for prediction in predictions_non_nms]
                predictions = []
                for prediction in predictions_non_nms:
                    if prediction['boxes'].shape[0]:
                        prediction['boxes'] /= 500
                        prediction['boxes'] = prediction['boxes'].clip(min=0, max=1)
                        boxes, scores, labels = soft_nms([prediction['boxes'].tolist()], 
                                                         [prediction['scores'].tolist()],
                                                         [prediction['labels'].tolist()], 
                                                         iou_thr=0.35, 
                                                         sigma=0.1, 
                                                         thresh=0.001)
                        prediction['boxes'] *= 500
                        prediction['boxes'] = torch.from_numpy(boxes)
                        prediction['scores'] = torch.from_numpy(scores)
                        prediction['labels'] = torch.from_numpy(labels)

                    predictions.append(prediction)
            
                record = self._compute_metrics(predictions, targets)
                record['loss'] = loss.item()
                self._update_records(record, batch_size)

                if i == n_batch_to_log and self.global_rank == 0:
                    j = torch.randint(0, batch_size, (1,)).item()
                    self._log_images(rgbs[j], targets[j], predictions[j])

        if not self.scheduler is None and self.stage == 'train':
            self.scheduler.step()
 
    def _compute_metrics(self, predictions, targets):
        record = super()._compute_metrics(predictions, targets)

        record['MAE'] = torch.tensor(0.0)
        for prediction, target in zip(predictions, targets):
            record['MAE'] += torch.sum(torch.abs(torch.bincount(prediction['labels'] - 1, minlength=3) - torch.bincount(target['labels'] - 1, minlength=3)))
        # predictions = []

        # for target, output in zip(targets, outputs):
  
        #     predictions.append({
        #         'pred_bboxes': output['boxes'].data.to(torch.int32),
        #         'gt_bboxes'  : target['boxes'].to(torch.int32),
        #         'scores'     : output['scores'].data
        #     })

        # record['mAP'] = torch.from_numpy(calculate_mAP(all_predictions, score_threshold=0.5))

        return record

    def _init_records(self) -> None:
        super()._init_records()

        self.records.update({'MAE' : torch.tensor(0.0)})

    def _log_images(self, rgb, target, prediction):
        target = {key : value.cpu().tolist() for key, value in target.items()}
        prediction = {key : value.cpu().tolist() for key, value in prediction.items()}
        composite = imgs2fig(rgb, {'PREDICTION': prediction, 'TARGET': target})
        self.logger[f'images/{self.stage}'].append(composite)
        
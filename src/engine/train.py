import torch
import torch.nn as nn

from ensemble_boxes import soft_nms

from .base import BaseEngine
from .utils import custom_nms, filtering_by_mask, process_detr_targets, process_detr_predictions
from ..utils import imgs2fig

class FasterRCNN_TorchVision_Engine(BaseEngine):
    def __init__(self, device, model, optimizer, criterion, scheduler, logger=None):
        super(FasterRCNN_TorchVision_Engine, self).__init__(device, model, optimizer, criterion, scheduler, logger)

        self.main_metric = 'MAE'
        self.best_metric = float("inf")
        self.criteria = lambda x,y : x < y

    def _run_epoch(self, loader) -> None:
        n_batch_to_log = torch.randint(0, len(loader), (1,)).item()

        for i, (features, targets, rgbs, nd_masks) in enumerate(loader):
            
            features = [feature.to(self.local_rank) for feature in features]
            nd_masks = [nd_mask.to(self.local_rank) for nd_mask in nd_masks]
            targets = [{k: v.to(self.local_rank) for k, v in t.items()} for t in targets]
            batch_size = len(features)

            self.model.train()
            losses = self.model(features, targets)
            loss = sum(loss for loss in losses.values())

            if self.stage == 'train':
                if loss == 0 or not torch.isfinite(loss):
                    continue

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            self.model.eval()
            with torch.no_grad():
                predictions = self.model(features)
                predictions = filtering_by_mask(predictions, nd_masks)
                predictions = custom_nms(predictions, trash_thr=0.01)
            
                record = self._compute_metrics(predictions, targets)
                record['loss'] = loss.item()
                self._update_records(record, batch_size)

                if i == n_batch_to_log and self.global_rank == 0:
                    j = torch.randint(0, batch_size, (1,)).item()
                    self._log_images(rgbs[j], targets[j], predictions[j])

        if not self.scheduler is None and self.stage == 'train':
            self.scheduler.step()
 
    def _compute_metrics(self, predictions, targets):
        record = super()._compute_metrics(predictions, targets)

        record['MAE'] = torch.tensor(0.0, device=self.local_rank)
        for prediction, target in zip(predictions, targets):
            record['MAE'] += torch.sum(torch.abs(torch.bincount(prediction['labels'] - 1, minlength=3) - torch.bincount(target['labels'] - 1, minlength=3)))
        # predictions = []

        # for target, output in zip(targets, outputs):
  
        #     predictions.append({
        #         'pred_bboxes': output['boxes'].data.to(torch.int32),
        #         'gt_bboxes'  : target['boxes'].to(torch.int32),
        #         'scores'     : output['scores'].data
        #     })

        # record['mAP'] = torch.from_numpy(calculate_mAP(all_predictions, score_threshold=0.5))

        return record

    def _init_records(self) -> None:
        super()._init_records()

        self.records.update({'MAE' : torch.tensor(0.0, device=self.local_rank)})

    def _log_images(self, rgb, target, prediction):
        target = {key : value.cpu().tolist() for key, value in target.items()}
        prediction = {key : value.cpu().tolist() for key, value in prediction.items()}
        composite = imgs2fig(rgb, {'PREDICTION': prediction, 'TARGET': target})
        self.logger[f'images/{self.stage}'].append(composite)

class DETR_Engine(FasterRCNN_TorchVision_Engine):
    def __init__(self, device, model, optimizer, criterion, scheduler, processor, logger=None):
        super(DETR_Engine, self).__init__(device, model, optimizer, criterion, scheduler, logger)

        self.processor = processor

    def _run_epoch(self, loader) -> None:
        n_batch_to_log = torch.randint(0, len(loader), (1,)).item()

        for i, (features, targets, rgbs, nd_masks) in enumerate(loader):
            
            features = features.to(self.local_rank)
            targets = [{k: v.to(self.local_rank) for k, v in t.items()} for t in targets]
            batch_size = features.shape[0]

            output = self.model(pixel_values=features, pixel_mask=None, labels=targets)
            loss = output.loss
            loss_dict = output.loss_dict

            if self.stage == 'train':
                if loss == 0 or not torch.isfinite(loss):
                    continue

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            orig_target_sizes = torch.stack([target["orig_size"] for target in targets], dim=0)
            predictions = self.processor.post_process_object_detection(output, target_sizes=orig_target_sizes, threshold=0.75)
            predictions = process_detr_predictions(predictions)
            predictions = filtering_by_mask(predictions, nd_masks)
            predictions = custom_nms(predictions, trash_thr=0.01)
            targets = process_detr_targets(targets)
        
            record = self._compute_metrics(predictions, targets)
            record['loss'] = loss.item()
            record.update({k: v.item() for k, v in loss_dict.items()})
            self._update_records(record, batch_size)

            if i == n_batch_to_log and self.global_rank == 0:
                j = torch.randint(0, batch_size, (1,)).item()
                self._log_images(rgbs[j], targets[j], predictions[j])

        if not self.scheduler is None and self.stage == 'train':
            self.scheduler.step()

    def _init_records(self) -> None:
        super(DETR_Engine, self)._init_records()

        self.records.update({'loss_ce'           : torch.tensor(0.0, device=self.local_rank)})
        self.records.update({'loss_bbox'         : torch.tensor(0.0, device=self.local_rank)})
        self.records.update({'loss_giou'         : torch.tensor(0.0, device=self.local_rank)})
        self.records.update({'cardinality_error' : torch.tensor(0.0, device=self.local_rank)})

class DETR_base_engine(FasterRCNN_TorchVision_Engine):
    def __init__(self, device, model, optimizer, criterion, scheduler, processor, class_weights, logger=None):
        super(DETR_base_engine, self).__init__(device, model, optimizer, criterion, scheduler, logger)

        self.processor = processor
        self.class_weights = torch.tensor(class_weights)

    def _run_epoch(self, loader) -> None:
        n_batch_to_log = torch.randint(0, len(loader), (1,)).item()

        for i, batch in enumerate(loader):
            
            pixel_values = batch["pixel_values"].to(self.local_rank)
            pixel_mask = batch["pixel_mask"].to(self.local_rank)
            rgbs = batch["rgb"]
            targets = [{k: v.to(self.local_rank) for k, v in t.items()} for t in batch["labels"]]
            batch_size = pixel_values.shape[0]

            outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=targets, class_weights=self.class_weights)

            loss = outputs.loss
            loss_dict = outputs.loss_dict

            if self.stage == 'train':
                if loss == 0 or not torch.isfinite(loss):
                    continue

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            orig_target_sizes = torch.stack([target["size"] for target in targets], dim=0)
            predictions = self.processor.post_process_object_detection(outputs, target_sizes=orig_target_sizes, threshold=0.5)

            predictions = process_detr_predictions(predictions)
            predictions = custom_nms(predictions, trash_thr=0.01, format='xywh')
            targets = process_detr_targets(targets)

            record = self._compute_metrics(predictions, targets)
            record['loss'] = loss.item()
            record.update({k: v.item() for k, v in loss_dict.items()})
            self._update_records(record, batch_size)

            if i == n_batch_to_log and self.global_rank == 0:
                j = torch.randint(0, batch_size, (1,)).item()
                self._log_images(rgbs[j], targets[j], predictions[j])

        if not self.scheduler is None and self.stage == 'train':
            self.scheduler.step()

    def _init_records(self) -> None:
        super(DETR_base_engine, self)._init_records()

        self.records.update({'loss_ce'           : torch.tensor(0.0, device=self.local_rank)})
        self.records.update({'loss_bbox'         : torch.tensor(0.0, device=self.local_rank)})
        self.records.update({'loss_giou'         : torch.tensor(0.0, device=self.local_rank)})
        self.records.update({'cardinality_error' : torch.tensor(0.0, device=self.local_rank)})


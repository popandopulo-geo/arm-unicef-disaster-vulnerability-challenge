import torch
import torch.nn as nn

from .base import BaseEngine
from ..utils import imgs2fig

class FasterRCNN_TorchVision_Engine(BaseEngine):
    def __init__(self, device, model, optimizer, criterion, scheduler, logger=None):
        super(SegmentationAgent, self).__init__(device, model, optimizer, criterion, scheduler, logger)

        self.main_metric = 'MAE'
        self.criteria = lambda x,y : x < y

    def _run_epoch(self, loader) -> None:
        n_batch_to_log = torch.randint(0, len(loader), (1,)).item()

        for i, (features, bboxes, labels) in enumerate(loader):
            
            features = features.to(self.local_rank)
            bboxes = bboxes.to(self.local_rank)
            labels = labels.to(self.local_rank)

            features = list(features)
            targets = [{'boxes' : box, 'labels' : label} for box, label in zip(bboxes, labels)]

            outputs = self.model(features, targets)
            loss = outputs.values().sum()
    
            if self.stage == 'train':
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            features = features.detach()
            targets = targets.detach()
            outputs = outputs.detach()

            probabilities = nn.Sigmoid()(outputs)
            predictions = torch.where(probabilities < self.threshold, 0, 1)
            
            record = self._compute_metrics(predictions, targets, masks)
            record['loss'] = loss.item()

            batch_size = targets.shape[0]
            self._update_records(record, 
                                 batch_size,
                                 targets.flatten().cpu(), 
                                 probabilities.flatten().cpu(),
                                 masks.flatten().cpu())

            targets = torch.where(masks == 0, 2, targets)
            predictions = torch.where(masks == 0, 2, predictions)

            masks = torch.squeeze(masks, dim=1)
            targets = torch.squeeze(targets, dim=1)
            predictions = torch.squeeze(predictions, dim=1)

            if i == n_batch_to_log and self.global_rank == 0:
                j = torch.randint(0, batch_size, (1,)).item()
                self._log_images(rgbs[j].cpu(), targets[j].cpu(), predictions[j].cpu())
        
        if not self.scheduler is None and self.stage == 'train':
            self.scheduler.step()

    def _compute_metrics(self, predictions, targets, masks):
        batch_size = targets.shape[0]

        predictions = predictions.reshape(batch_size, -1)[torch.where(masks.reshape(batch_size, -1) == 1)]
        targets = targets.reshape(batch_size, -1)[torch.where(masks.reshape(batch_size, -1) == 1)]

        record = super()._compute_metrics(predictions, targets)

        record.update({
            'F1-score mean'  : self.f1score_mean(predictions, targets) * batch_size,
            'Jaccard mean'   : self.jaccard_mean(predictions, targets) * batch_size,
            'Precision mean' : self.precision_mean(predictions, targets) * batch_size,
            'Recall mean'    : self.recall_mean(predictions, targets) * batch_size
        })

        class_1, class_2 = self.f1score_class(predictions, targets) * batch_size
        record.update({'F1-score Soft' : class_1, 'F1-score Con.' : class_2})
        class_1, class_2 = self.jaccard_class(predictions, targets) * batch_size
        record.update({'Jaccard Soft' : class_1, 'Jaccard Con.' : class_2})
        class_1, class_2 = self.precision_class(predictions, targets) * batch_size
        record.update({'Precision Soft' : class_1, 'Precision Con.' : class_2})
        class_1, class_2 = self.recall_class(predictions, targets) * batch_size
        record.update({'Recall Soft' : class_1, 'Recall Con.' : class_2})

        return record

    def _estimate_threshold(self):

        best_f1 = 0
            
        for threshold in self.threshold_range:
            
            predictions = torch.where(self.accumulated_prob < threshold, 0, 1)
            f1 = self.f1score_mean(predictions, self.accumulated_target)

            if f1 > best_f1:
                self.threshold = threshold
                best_f1 = f1

        self.threshold = self.threshold.to(self.local_rank)
        if self.world_size > 1:
            dist.broadcast(self.threshold, src=0)

    def _init_records(self) -> None:
        super()._init_records()

        self.records.update({
            'F1-score mean'    : torch.tensor(0.0, device=self.local_rank),
            'Jaccard mean'     : torch.tensor(0.0, device=self.local_rank),
            'F1-score Soft'    : torch.tensor(0.0, device=self.local_rank),
            'F1-score Con.'    : torch.tensor(0.0, device=self.local_rank),
            'Jaccard Soft'     : torch.tensor(0.0, device=self.local_rank),
            'Jaccard Con.'     : torch.tensor(0.0, device=self.local_rank),
            'Precision Soft'   : torch.tensor(0.0, device=self.local_rank),
            'Precision Con.'   : torch.tensor(0.0, device=self.local_rank),
            'Recall Soft'      : torch.tensor(0.0, device=self.local_rank),
            'Recall Con.'      : torch.tensor(0.0, device=self.local_rank),
        })

        self.local_accumulated_target = torch.empty(0)
        self.local_accumulated_prob = torch.empty(0)
        self.local_accumulated_mask = torch.empty(0)

    def _update_records(self, record, n_samples, targets, probabilities, masks) -> None:
        super()._update_records(record, n_samples)
        
        if self.stage == 'valid':
        
            self.local_accumulated_target = torch.hstack([self.local_accumulated_target, targets])
            self.local_accumulated_prob = torch.hstack([self.local_accumulated_prob, probabilities])
            self.local_accumulated_mask = torch.hstack([self.local_accumulated_mask, masks])

    def _reduce_records(self) -> None:
        super()._reduce_records()
        
        if self.stage == 'valid':

            if self.world_size > 1:
            
                self.local_accumulated_mask = self.local_accumulated_mask.to(self.local_rank)
                self.local_accumulated_target = self.local_accumulated_target.to(self.local_rank)
                self.local_accumulated_prob = self.local_accumulated_prob.to(self.local_rank)
                local_accumulated = torch.vstack([self.local_accumulated_mask, self.local_accumulated_target, self.local_accumulated_prob])
                
                if self.global_rank == 0:
                    
                    accumulated = [torch.zeros_like(local_accumulated, device="cuda:0") for _ in range(self.world_size)] # ? local_rank
                    dist.gather(local_accumulated, accumulated, dst=0)
                    
                    accumulated_mask = torch.hstack([accumulated[i][0] for i in range(self.world_size)]).cpu()
                    self.accumulated_target = torch.hstack([accumulated[i][1] for i in range(self.world_size)]).cpu()
                    self.accumulated_prob = torch.hstack([accumulated[i][2] for i in range(self.world_size)]).cpu()

                    self.accumulated_target = self.accumulated_target[torch.where(accumulated_mask == 1)]
                    self.accumulated_prob = self.accumulated_prob[torch.where(accumulated_mask == 1)]

                    self._estimate_threshold()

                    self.accumulated_pred = torch.where(self.accumulated_prob < self.threshold.cpu(), 0, 1)
                    self.accumulated_pred = self.accumulated_pred.numpy()
                    self.accumulated_target = self.accumulated_target.numpy()
                    
                else:

                    dist.gather(local_accumulated, dst=0)
                    dist.broadcast(self.threshold, src=0) 
                    
            else:

                self.accumulated_mask = self.local_accumulated_mask
                self.accumulated_target = self.local_accumulated_target
                self.accumulated_prob = self.local_accumulated_prob

                self.accumulated_target = self.accumulated_target[torch.where(self.accumulated_mask == 1)]
                self.accumulated_prob = self.accumulated_prob[torch.where(self.accumulated_mask == 1)]

                self._estimate_threshold()

    def _log_images(self, rgb, target, prediction):
        imgs = [
            {'image' : rgb,        'cmap' : None,                                   'legend' : None,                                              'name' : 'RGB'},
            {'image' : prediction, 'cmap' : {'black': 2, 'green': 0, 'yellow' : 1}, 'legend' : {2: 'No data', 0: 'Soft-leaved', 1: 'Coniferous'}, 'name' : 'PREDICTION'},
            {'image' : target,     'cmap' : {'black': 2, 'green': 0, 'yellow' : 1}, 'legend' : {2: 'No data', 0: 'Soft-leaved', 1: 'Coniferous'}, 'name' : 'TARGET'},
        ]
        composite = imgs2fig(imgs)
        self.logger[f'images/{self.stage}'].append(composite)
        
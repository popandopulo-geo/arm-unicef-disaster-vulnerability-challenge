import pandas as pd
import numpy as np
import os
import itertools
from socket import gethostname
import neptune
import copy
import json
import gc

import torch
import torch.nn as nn
from torch.distributed import is_initialized
from transformers import DetrImageProcessor
import albumentations as A

from src.data.datasets import RoofsDataset_DETR_base
from src.data.utils import collate_fn_detr
from src.engine.train import DETR_base_engine
from src.network import DetrForObjectDetection
from src.scheduler import GradualWarmupScheduler
from src.utils import dict2str, estimate_maximum_batch_size, seed_everything

SEED = 17112000
SPLITS_ROOT = 'data/splits'
IMAGES_ROOT = 'data/Images'

def main():
    seed_everything(SEED)
    torch.cuda.empty_cache()
    gc.collect()

    world_size = int(os.environ["WORLD_SIZE"])
    global_rank = int(os.environ["SLURM_PROCID"])
    gpus_per_node = int(os.environ["SLURM_NTASKS_PER_NODE"])

    assert gpus_per_node <= torch.cuda.device_count()
    print(f"Hello from rank {global_rank} of {world_size} on {gethostname()} where there are" \
          f" {gpus_per_node} allocated GPUs per node.")

    if world_size > 1:
        print("DDP is using")
        ddp_setup(world_size, global_rank)

        if global_rank == 0: 
            print(f"\nGroup initialized? {is_initialized()}")
            
    else:
        print("DDP is not using")

    local_rank = global_rank - gpus_per_node * (global_rank // gpus_per_node)
    torch.cuda.set_device(local_rank)

    print(f"host: {gethostname()}, rank: {global_rank}, local_rank: {local_rank}")

    parameters = {
        "batch_size"     : 'auto',
        "n_epochs"       : 200,
        "lr"             : 2e-4, 
        "lr_backbone"    : 1e-5,
        "weight_decay"   : 1e-4,
        "train_csv"      : "train_bbox_only_nc.json",
        "valid_csv"      : "valid.json",
        "in_size"        : (1000, 1000),
        "weights"        : [49.5867,  0.3730,  3.3486]
    }

    model = {
        'backbone' : 'resnet50',
        'name'     : 'DETR',
        'loss'     : 'DETR loss, weighted'
    }

    network = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50", num_labels=3, revision="no_timm", ignore_mismatched_sizes=True)
    network = network.to(local_rank)

    param_dicts = [
        {"params": [p for n, p in network.named_parameters() if "backbone" not in n and p.requires_grad]},
        {
            "params": [p for n, p in network.named_parameters() if "backbone" in n and p.requires_grad],
            "lr": parameters["lr_backbone"],
        },
    ]
    optimizer = torch.optim.AdamW(param_dicts, lr=parameters["lr"], weight_decay=parameters["weight_decay"])
    scheduler = None

    processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
    collate_fn = collate_fn_detr(processor)

    if parameters['batch_size'] == 'auto':
        parameters['batch_size'] = estimate_maximum_batch_size(network, local_rank, (3,) + parameters['in_size'])
        # parameters['batch_size'] *= 2

    train_loader_params = {
        "img_folder"  : IMAGES_ROOT,
        "ann_file"    : os.path.join(SPLITS_ROOT, parameters["train_csv"]),
        "processor"   : processor,
        "batch_size"  : parameters['batch_size'], 
        "shuffle"     : True,
        "collate_fn"  : collate_fn,
        "keep"        : [1, 2, 3]
    }
    valid_loader_params = {
        "img_folder"  : IMAGES_ROOT,
        "ann_file"    : os.path.join(SPLITS_ROOT, parameters["valid_csv"]),
        "batch_size"  : parameters['batch_size'], 
        "processor"   : processor,
        "collate_fn"  : collate_fn,
        "keep"        : [1, 2, 3]
    }
    train_loader = RoofsDataset_DETR_base.get_dataloader(**train_loader_params)
    valid_loader = RoofsDataset_DETR_base.get_dataloader(**valid_loader_params)
    
    if global_rank == 0:
        logger = neptune.init_run(
            project="GreekAI/ZINDI-arm",
            description='DETR base, class_weights + nms, postprocess thr is 0.5', 
            source_files=["src/*.py", "src/**/*.py", "train.py", "launch.sh"],
            with_id='ARM-19',
            api_token="eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiNGRhMzc1Yi00YWI2LTQ3NDktODJiMy1lMzM1Y2Y4ZGU1NmYifQ==",
        ) 

        fields = ['parameters', 'model', 'metrics', 'monitoring', 'images', 'snapshots', 'matric']
        for field in fields:
            try:
                del logger[field]
            except neptune.exceptions.MetadataInconsistency:
                pass

        logger['parameters'] = dict2str(copy.deepcopy(parameters))
        logger['model'] = dict2str(copy.deepcopy(model))
    
        logger.wait()

    else:
        logger = None

    agent = DETR_base_engine(local_rank, network, optimizer, None, scheduler, processor, parameters['weights'], logger)
    agent.train(parameters['n_epochs'], train_loader, valid_loader)
    
    if world_size > 1:
        ddp_destroy()

if __name__ == '__main__':
    main()